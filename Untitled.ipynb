{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4990afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205340b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has outcome 7832\n",
      "No outcome 5403298\n",
      "Number of covariates : 8380\n",
      "Has outcome 267\n",
      "No outcome 175770\n",
      "            covariateValue                                                  \\\n",
      "covariateId    22281101    22281102    22281103    22281104    22281105      \n",
      "patient                                                                      \n",
      "1.0                    0.0         0.0         0.0         0.0         0.0   \n",
      "2.0                    0.0         0.0         0.0         0.0         0.0   \n",
      "3.0                    0.0         0.0         0.0         0.0         0.0   \n",
      "4.0                    0.0         0.0         0.0         0.0         0.0   \n",
      "5.0                    0.0         0.0         0.0         0.0         0.0   \n",
      "...                    ...         ...         ...         ...         ...   \n",
      "176489.0               0.0         0.0         0.0         0.0         0.0   \n",
      "176490.0               0.0         0.0         0.0         0.0         0.0   \n",
      "176491.0               0.0         0.0         0.0         0.0         0.0   \n",
      "176492.0               0.0         0.0         0.0         0.0         0.0   \n",
      "176493.0               0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                                                                         ...  \\\n",
      "covariateId 22281106    23325101    23325102    23325103    23325104     ...   \n",
      "patient                                                                  ...   \n",
      "1.0                 0.0         0.0         0.0         0.0         0.0  ...   \n",
      "2.0                 0.0         1.0         0.0         0.0         0.0  ...   \n",
      "3.0                 0.0         0.0         0.0         0.0         0.0  ...   \n",
      "4.0                 0.0         0.0         0.0         0.0         0.0  ...   \n",
      "5.0                 0.0         0.0         0.0         0.0         0.0  ...   \n",
      "...                 ...         ...         ...         ...         ...  ...   \n",
      "176489.0            0.0         0.0         0.0         0.0         0.0  ...   \n",
      "176490.0            0.0         1.0         0.0         0.0         0.0  ...   \n",
      "176491.0            0.0         0.0         0.0         0.0         0.0  ...   \n",
      "176492.0            0.0         1.0         0.0         0.0         0.0  ...   \n",
      "176493.0            0.0         0.0         0.0         0.0         0.0  ...   \n",
      "\n",
      "                                                                         \\\n",
      "covariateId 46273592102 46273592103 46273592104 46273592105 46286052101   \n",
      "patient                                                                   \n",
      "1.0                 0.0         0.0         0.0         0.0         0.0   \n",
      "2.0                 0.0         0.0         0.0         0.0         0.0   \n",
      "3.0                 0.0         0.0         0.0         0.0         0.0   \n",
      "4.0                 0.0         0.0         0.0         0.0         0.0   \n",
      "5.0                 0.0         0.0         0.0         0.0         0.0   \n",
      "...                 ...         ...         ...         ...         ...   \n",
      "176489.0            0.0         0.0         0.0         0.0         0.0   \n",
      "176490.0            0.0         0.0         0.0         0.0         0.0   \n",
      "176491.0            0.0         0.0         0.0         0.0         0.0   \n",
      "176492.0            0.0         0.0         0.0         0.0         0.0   \n",
      "176493.0            0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "                                                                         \n",
      "covariateId 46286052102 46286052103 46286052104 46286052105 46286052106  \n",
      "patient                                                                  \n",
      "1.0                 0.0         0.0         0.0         0.0         0.0  \n",
      "2.0                 0.0         0.0         0.0         0.0         0.0  \n",
      "3.0                 0.0         0.0         0.0         0.0         0.0  \n",
      "4.0                 0.0         0.0         0.0         0.0         0.0  \n",
      "5.0                 0.0         0.0         0.0         0.0         0.0  \n",
      "...                 ...         ...         ...         ...         ...  \n",
      "176489.0            0.0         0.0         0.0         0.0         0.0  \n",
      "176490.0            0.0         0.0         0.0         0.0         0.0  \n",
      "176491.0            0.0         0.0         0.0         0.0         0.0  \n",
      "176492.0            0.0         0.0         0.0         0.0         0.0  \n",
      "176493.0            0.0         0.0         0.0         0.0         0.0  \n",
      "\n",
      "[176037 rows x 8380 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pick a dataset and outcome file\n",
    "\n",
    "data = pd.read_csv('cov_merged.csv')\n",
    "target = pd.read_csv('outcomes.csv')\n",
    "\n",
    "\n",
    "# Get the concept and analysis id from the covariate id\n",
    "data_concepts = []\n",
    "windows = []\n",
    "for i in data['covariateId']:\n",
    "    concept = i // 1000\n",
    "    window = i % 1000\n",
    "    data_concepts.append(concept)\n",
    "    windows.append(window)\n",
    "\n",
    "# Create windows to represent analysis ids\n",
    "analysisId_to_window = {101: \"all\", 102: '365d', 103: '180d', 104: '030d', 105: 'all',\n",
    "                        106: '365d', 107: '180d', 108: '030d'}\n",
    "\n",
    "# Create observations data file from data file\n",
    "observation = pd.DataFrame()\n",
    "observation['conceptId'] = data_concepts\n",
    "observation['analysisId'] = windows\n",
    "observation['window'] = observation['analysisId'].apply(lambda x: analysisId_to_window.get(x, 'Unknown'))\n",
    "observation['covariateValue'] = 1\n",
    "observation['patient'] = data['rowId']\n",
    "observation['covariateId'] = data['covariateId']\n",
    "\n",
    "# Pick time window\n",
    "# observation = observation[observation['window'] == \"all\"]\n",
    "\n",
    "# Creating outcomes list\n",
    "outcomes = []\n",
    "has_outcome = 0\n",
    "no_outcome = 0\n",
    "for i in observation['patient']:\n",
    "    if i in target['rowId'].values:\n",
    "        if target.loc[target['rowId'] == i, 'daysToEvent'].values[0] < 1825:\n",
    "            outcomes.append(1)\n",
    "            has_outcome += 1\n",
    "        else:\n",
    "            outcomes.append(0)\n",
    "            no_outcome += 1\n",
    "    else:\n",
    "        outcomes.append(0)\n",
    "        no_outcome += 1\n",
    "\n",
    "print(f'Has outcome {has_outcome}')\n",
    "print(f'No outcome {no_outcome}')\n",
    "\n",
    "\n",
    "    # From long to wide format\n",
    "observation = observation.pivot(index=['patient'], columns=['covariateId'], values=['covariateValue'])\n",
    "# observation = observation['covariateValue']\n",
    "\n",
    "# Replace NaN values with 0\n",
    "for i in observation.columns:\n",
    "    observation[i] = observation[i].fillna(0)\n",
    "\n",
    "print('Number of covariates :', len(observation.columns))\n",
    "\n",
    "# Creating outcomes list\n",
    "outcomes = []\n",
    "has_outcome = 0\n",
    "no_outcome = 0\n",
    "for i in observation.index:\n",
    "    if i in target['rowId'].values:\n",
    "        if target.loc[target['rowId'] == i, 'daysToEvent'].values[0] < 1825:\n",
    "            outcomes.append(1)\n",
    "            has_outcome += 1\n",
    "        else:\n",
    "            outcomes.append(0)\n",
    "            no_outcome += 1\n",
    "    else:\n",
    "        outcomes.append(0)\n",
    "        no_outcome += 1\n",
    "\n",
    "print(f'Has outcome {has_outcome}')\n",
    "print(f'No outcome {no_outcome}')\n",
    "print(observation)\n",
    "\n",
    "\n",
    "# Split the data in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(observation, outcomes, stratify=outcomes, random_state=1, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349279a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea65898",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (132027, 500), indices imply (132027, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_test_reduced \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      5\u001b[0m cols \u001b[38;5;241m=\u001b[39m [(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m X_train_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m cols \u001b[38;5;241m=\u001b[39m [(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m     10\u001b[0m X_test_reduced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test_reduced, columns\u001b[38;5;241m=\u001b[39mcols)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (132027, 500), indices imply (132027, 100)"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=500)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "cols = [(x * 1000) - 1 for x in range(2, 100 + 2)]\n",
    "X_train_reduced = pd.DataFrame(X_train_reduced, columns=cols)\n",
    "\n",
    "\n",
    "cols = [(x * 1000) - 1 for x in range(2, 100 + 2)]\n",
    "X_test_reduced = pd.DataFrame(X_test_reduced, columns=cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cbc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_penalty = 'l1'\n",
    "lr_solver = \"liblinear\"\n",
    "model = LogisticRegression(penalty=lr_penalty, solver=lr_solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd776703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on train data\n",
    "model.fit(data_train, outcomes_train)\n",
    "\n",
    "# Get model coefficients\n",
    "model_coefficients = model.coef_[0]\n",
    "print(model.coef_)\n",
    "\n",
    "number_model_features = len(set(model_coefficients))\n",
    "\n",
    "print('Number of model features:', number_model_features)\n",
    "\n",
    "# Get train probabilities\n",
    "y_prob_train = model.predict_proba(data_train)\n",
    "\n",
    "y_pred_train = model.predict(data_train)\n",
    "\n",
    "# Get the train auc score\n",
    "train_auc = roc_auc_score(outcomes_train, y_prob_train[:, 1])\n",
    "print(train_auc)\n",
    "\n",
    "# Get test probabilities\n",
    "y_prob_test = model.predict_proba(data_test)\n",
    "\n",
    "y_pred_test = model.predict(data_test)\n",
    "\n",
    "# Get the test auc score\n",
    "test_auc = roc_auc_score(outcomes_test, y_prob_test[:, 1])\n",
    "print(test_auc)\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision_test, recall_test, _ = precision_recall_curve(outcomes_test, y_prob_test[:, 1])\n",
    "\n",
    "# Calculate AUPRC\n",
    "auprc_test_score = auc(recall_test, precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(observation)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.savefig(\"explained_var.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fdcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true = [0, 1, 1, 0, 1]  # example ground truth\n",
    "y_scores = [0, 0, 0, 0, 0]  # all predicted scores = 0\n",
    "\n",
    "roc_auc_score(y_true, y_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
