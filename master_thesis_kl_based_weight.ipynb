{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feef4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018236b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rowId  covariateId  covariateValue  \\\n",
      "0          3938.0   4083311102               1   \n",
      "1        175397.0     81380102               1   \n",
      "2         23031.0   4145418102               1   \n",
      "3        152472.0    135473102               1   \n",
      "4         60021.0   4213101102               1   \n",
      "...           ...          ...             ...   \n",
      "5411125   67932.0    378253104               1   \n",
      "5411126  135007.0   4211852104               1   \n",
      "5411127  127381.0    197988104               1   \n",
      "5411128   20208.0    201826104               1   \n",
      "5411129  161935.0    440005104               1   \n",
      "\n",
      "                                             covariateName  analysisId  \\\n",
      "0        condition_occurrence during day -365 through -...         102   \n",
      "1        condition_occurrence during day -365 through -...         102   \n",
      "2        condition_occurrence during day -365 through -...         102   \n",
      "3        condition_occurrence during day -365 through -...         102   \n",
      "4        condition_occurrence during day -365 through -...         102   \n",
      "...                                                    ...         ...   \n",
      "5411125  condition_occurrence during day -30 through -1...         104   \n",
      "5411126  condition_occurrence during day -30 through -1...         104   \n",
      "5411127  condition_occurrence during day -30 through -1...         104   \n",
      "5411128  condition_occurrence during day -30 through -1...         104   \n",
      "5411129  condition_occurrence during day -30 through -1...         104   \n",
      "\n",
      "         conceptId  \n",
      "0          4083311  \n",
      "1            81380  \n",
      "2          4145418  \n",
      "3           135473  \n",
      "4          4213101  \n",
      "...            ...  \n",
      "5411125     378253  \n",
      "5411126    4211852  \n",
      "5411127     197988  \n",
      "5411128     201826  \n",
      "5411129     440005  \n",
      "\n",
      "[5411130 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cov_merged.csv')\n",
    "target = pd.read_csv('outcomes.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678f7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         conceptId  analysisId window  covariateValue   patient  covariateId\n",
      "0          4083311         102   365d               1    3938.0   4083311102\n",
      "1            81380         102   365d               1  175397.0     81380102\n",
      "2          4145418         102   365d               1   23031.0   4145418102\n",
      "3           135473         102   365d               1  152472.0    135473102\n",
      "4          4213101         102   365d               1   60021.0   4213101102\n",
      "...            ...         ...    ...             ...       ...          ...\n",
      "5411125     378253         104   030d               1   67932.0    378253104\n",
      "5411126    4211852         104   030d               1  135007.0   4211852104\n",
      "5411127     197988         104   030d               1  127381.0    197988104\n",
      "5411128     201826         104   030d               1   20208.0    201826104\n",
      "5411129     440005         104   030d               1  161935.0    440005104\n",
      "\n",
      "[5411130 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create windows to represent analysis ids\n",
    "analysisId_to_window = {101: \"all\", 102: '365d', 103: '180d', 104: '030d', 105: 'all',\n",
    "                        106: '365d', 107: '180d', 108: '030d'}\n",
    "\n",
    "# Create observations data file from data file\n",
    "observation = pd.DataFrame()\n",
    "observation['conceptId'] = data['conceptId']\n",
    "observation['analysisId'] = data['analysisId']\n",
    "observation['window'] = data['analysisId'].apply(lambda x: analysisId_to_window.get(x, 'Unknown'))\n",
    "observation['covariateValue'] = 1\n",
    "observation['patient'] = data['rowId']\n",
    "observation['covariateId'] = data['covariateId']\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169255c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4257791\n",
      "656937\n",
      "385185\n",
      "111217\n"
     ]
    }
   ],
   "source": [
    "observation_all = observation[observation['window'] == \"all\"]\n",
    "print(len(observation_all))\n",
    "observation_365d = observation[observation['window'] == \"365d\"]\n",
    "print(len(observation_365d))\n",
    "observation_180d = observation[observation['window'] == \"180d\"]\n",
    "print(len(observation_180d))\n",
    "observation_030d = observation[observation['window'] == \"030d\"]\n",
    "print(len(observation_030d))\n",
    "\n",
    "# Pick time window\n",
    "chosen_window = \"365d\"\n",
    "observation = observation[observation['window'] == chosen_window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dae0f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has outcome 1174\n",
      "No outcome 655763\n"
     ]
    }
   ],
   "source": [
    "risk_window_end = 1825\n",
    "# Creating outcomes list\n",
    "outcomes = []\n",
    "has_outcome = 0\n",
    "no_outcome = 0\n",
    "for i in observation['patient']:\n",
    "    if i in target['rowId'].values:\n",
    "        if target.loc[target['rowId'] == i, 'daysToEvent'].values[0] < risk_window_end:\n",
    "            outcomes.append(1)\n",
    "            has_outcome += 1\n",
    "        else:\n",
    "            outcomes.append(0)\n",
    "            no_outcome += 1\n",
    "    else:\n",
    "        outcomes.append(0)\n",
    "        no_outcome += 1\n",
    "\n",
    "print(f'Has outcome {has_outcome}')\n",
    "print(f'No outcome {no_outcome}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3327df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "test_size = 0.25\n",
    "# Split the data in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(observation, outcomes, stratify=outcomes, random_state=random_state, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc953b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Load ancestor data\n",
    "ancestry = pd.read_csv(\"relations_ancestor_total.csv\")\n",
    "parentage = ancestry[ancestry['MIN_LEVELS_OF_SEPARATION'] == 1]\n",
    "\n",
    "print(len(set(parentage)))\n",
    "observed_concepts_train = X_train['conceptId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757fb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique ancestor concepts related to observed concepts\n",
    "relevant_concept_train = ancestry[ancestry['DESCENDANT_CONCEPT_ID'].isin(observed_concepts_train)][\n",
    "    'ANCESTOR_CONCEPT_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484d138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ancestry dataframe to include only relevant ancestor descendant relationships\n",
    "relevant_ancestry_train = ancestry[\n",
    "    ancestry['ANCESTOR_CONCEPT_ID'].isin(relevant_concept_train) | ancestry['DESCENDANT_CONCEPT_ID'].isin(\n",
    "        relevant_concept_train)]\n",
    "relevant_ancestry_train = relevant_ancestry_train.rename(\n",
    "    columns={'ANCESTOR_CONCEPT_ID': 'ancestor', 'DESCENDANT_CONCEPT_ID': 'descendent',\n",
    "             'MIN_LEVELS_OF_SEPARATION': 'minimum separation', 'MAX_LEVELS_OF_SEPARATION': 'maximum separation'}) \\\n",
    "    .drop(columns=['Unnamed: 0', 'CTID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86a5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter parentage dataframe to include only relevant parent-child relationships\n",
    "relevant_parentage_train = parentage[\n",
    "    parentage['ANCESTOR_CONCEPT_ID'].isin(relevant_concept_train) | parentage['DESCENDANT_CONCEPT_ID'].isin(\n",
    "        relevant_concept_train)]\n",
    "relevant_parentage_train = relevant_parentage_train.rename(columns={'ANCESTOR_CONCEPT_ID': 'parent', 'DESCENDANT_CONCEPT_ID': 'child'})\\\n",
    "    .drop(columns=['Unnamed: 0', 'MIN_LEVELS_OF_SEPARATION', 'MAX_LEVELS_OF_SEPARATION', 'CTID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c4e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "children_train = set(relevant_parentage_train['child'])\n",
    "parents_train = set(relevant_parentage_train['parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26989034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify leaf concepts\n",
    "leaf_concept_train = children_train - parents_train\n",
    "leaf_concepts_train = pd.DataFrame({\"id\": list(leaf_concept_train)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b406074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by patient and count cumulative concept count\n",
    "observed_concepts_per_patient = X_train.groupby([\"patient\", \"window\"]).agg(conceptcount=(\"conceptId\", \"nunique\")).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3263d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique patients per window\n",
    "train_patientcount = X_train.groupby(\"window\")['patient'].nunique().reset_index()\n",
    "train_patientcount = train_patientcount.rename(columns={'patient': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fde079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge observations with the compute unique concept count per patient\n",
    "train_observation_ancestor = X_train.merge(observed_concepts_per_patient, on=['patient', 'window'])\n",
    "train_observation_ancestor = train_observation_ancestor.merge(relevant_ancestry_train, left_on='conceptId', right_on='descendent')\\\n",
    "    .drop(columns=['descendent', 'minimum separation', 'maximum separation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a58fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weight of each concept by inverting the unique concept count\n",
    "train_observation_ancestor['weight'] = 1.0 / train_observation_ancestor['conceptcount']\n",
    "train_observation_ancestor = train_observation_ancestor.rename(columns={'conceptId': 'observed concept'})\n",
    "train_observation_ancestor = train_observation_ancestor.drop(columns=['conceptcount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6682087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate weighted concept values per patient\n",
    "train_per_patient_weighted_concept = train_observation_ancestor.groupby(['patient', 'window', 'ancestor']).agg(weight=('weight', 'sum')).reset_index()\n",
    "train_per_patient_weighted_concept = train_per_patient_weighted_concept.rename(columns={'ancestor': 'conceptId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3d1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge weighted concept values with patient count per window\n",
    "df_train_weighted_concept = train_per_patient_weighted_concept.merge(train_patientcount, on=\"window\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3496635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by window and concept and aggregate the weight\n",
    "train_weighted_concept = df_train_weighted_concept.groupby([\"window\", \"conceptId\"], as_index=False).agg(weight=(\"weight\", \"sum\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "897b8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize weights by dividing by patient count\n",
    "train_weighted_concept[\"weight\"] = train_weighted_concept[\"weight\"] / df_train_weighted_concept.groupby([\"window\", \"conceptId\"])[\"count\"].first().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d360185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for clarity in parent child relationships\n",
    "wcfp = train_weighted_concept.rename(columns={\"conceptId\": \"parent\", \"weight\": \"parent weight\"})\n",
    "wcfc = train_weighted_concept.rename(columns={\"conceptId\": \"child\", \"weight\": \"child weight\"})\n",
    "\n",
    "# Merge with parent child relationships\n",
    "df_wcfp = relevant_parentage_train.merge(wcfp, on=\"parent\")\n",
    "df_wcfc = df_wcfp.merge(wcfc, on=[\"child\", \"window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "526fb8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a weight of zero to leaf nodes\n",
    "leaf_df = leaf_concepts_train.merge(wcfp, left_on='id', right_on='parent').drop(columns=['parent'])\n",
    "leaf_df[\"child\"] = None\n",
    "leaf_df[\"child weight\"] = 0.0\n",
    "leaf_df = leaf_df.rename(columns={\"id\": \"parent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc386b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine hierarchical relationships and leaf concepts\n",
    "train_weighted_parentage = pd.concat([df_wcfc, leaf_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51558a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose parent weight and child weight\n",
    "parent_weight = 0.2\n",
    "child_weight = 0.5\n",
    "\n",
    "# Select concepts where parent weight is >= chosen parent weight and child weight < chosen child weight\n",
    "concept_selection = train_weighted_parentage[(train_weighted_parentage['parent weight'] >= parent_weight) & (child_weight > train_weighted_parentage['child weight'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a8f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only observed concepts\n",
    "observed = X_train['conceptId']\n",
    "# Select observed descendants\n",
    "observed_descendants = relevant_ancestry_train[relevant_ancestry_train['descendent'].isin(observed)]\n",
    "# Select concepts with observed descendants\n",
    "concepts_with_observed_descendants = observed_descendants['ancestor']\n",
    "# Selected concepts by knowledge dr\n",
    "selected_concepts_list = concept_selection['child']\n",
    "# Select only concepts that are selected with knowledge based dimension reduction technique\n",
    "selected_concepts_df = X_train[X_train['conceptId'].isin(selected_concepts_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18a4e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = []\n",
    "concept = []\n",
    "covariateId = []\n",
    "covariateValue = []\n",
    "analysisId = []\n",
    "\n",
    "for _, row in X_train.iterrows():\n",
    "\n",
    "    if row['conceptId'] in set(selected_concepts_list) and row['conceptId'] in set(concepts_with_observed_descendants):\n",
    "        patient.append(row['patient'])\n",
    "        concept.append(row['conceptId'])\n",
    "        covariateId.append(row['covariateId'])\n",
    "        analysisId.append(row['analysisId'])\n",
    "        covariateValue.append(1)\n",
    "    else:\n",
    "        patient.append(row['patient'])\n",
    "        concept.append(row['conceptId'])\n",
    "        covariateId.append(row['covariateId'])\n",
    "        analysisId.append(row['analysisId'])\n",
    "        covariateValue.append(0)\n",
    "        # pass\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['conceptId'] = concept\n",
    "df['analysisId'] = analysisId\n",
    "df['covariateValue'] = covariateValue\n",
    "df['patient'] = patient\n",
    "df['covariateId'] = covariateId\n",
    "\n",
    "X_train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98574d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144317\n"
     ]
    }
   ],
   "source": [
    "def pivot_covariates(df):\n",
    "    observation = df.pivot(index='patient', columns='covariateId', values='covariateValue')\n",
    "    return observation.fillna(0)\n",
    "\n",
    "X_train = pivot_covariates(X_train)\n",
    "X_test = pivot_covariates(X_test)\n",
    "\n",
    "print(len(X_train))\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50612afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outcomes(indexes):\n",
    "    outcomes = []\n",
    "    for i in indexes:\n",
    "        if i in target['rowId'].values:\n",
    "            days_to_event = target.loc[target['rowId'] == i, 'daysToEvent'].values[0]\n",
    "            outcomes.append(1 if days_to_event < risk_window_end else 0)\n",
    "        else:\n",
    "            outcomes.append(0)\n",
    "    return outcomes\n",
    "\n",
    "y_train = create_outcomes(X_train.index)\n",
    "y_test = create_outcomes(X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66f8d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144317\n",
      "144317\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fadd1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model, penalty, solver\n",
    "lr_penalty = 'l1'\n",
    "lr_solver = \"liblinear\"\n",
    "model = LogisticRegression(penalty=lr_penalty, solver=lr_solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c8c42c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "Number of model features: 1\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Fit model on train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get model coefficients\n",
    "model_coefficients = model.coef_[0]\n",
    "print(model.coef_)\n",
    "\n",
    "number_model_features = len(set(model_coefficients))\n",
    "\n",
    "print('Number of model features:', number_model_features)\n",
    "\n",
    "# Get train probabilities\n",
    "y_prob_train = model.predict_proba(X_train)\n",
    "\n",
    "# Get ths train auc score\n",
    "train_auc = roc_auc_score(y_train, y_prob_train[:, 1])\n",
    "print(train_auc)\n",
    "\n",
    "# Get test probabilities\n",
    "y_prob_test = model.predict_proba(X_test)\n",
    "\n",
    "# Get ths test auc score\n",
    "test_auc = roc_auc_score(y_test, y_prob_test[:, 1])\n",
    "print(test_auc)\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_prob_test[:, 1])\n",
    "\n",
    "# Calculate AUPRC\n",
    "auprc_test_score = auc(recall_test, precision_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
